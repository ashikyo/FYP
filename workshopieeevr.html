<!DOCTYPE html>
<html lang = "en">
   <head>
      
<!--       <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"> -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/css/uikit.min.css" />
	<script src="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/js/uikit.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/js/uikit-icons.min.js"></script>
   <script src="./libs/jquery-3.5.1.min.js" type="text/javascript"></script>
	<link href="./style.css" rel="stylesheet">
   </head>

   <body>
    <header>
      <div id="logo-area" uk-grid>
       <a href="https://locomotionvault.github.io/" class="uk-logo uk-width-2-3">Locomotion Vault</a>
          <!--  <div class="uk-width-1-3 uk-margin-small-bottom" uk-grid>
           </div> -->
      </div>
    </header>

    <div class="teaser">
      <img src="./Gifs/TeaserFull.jpg"></img>
    </div>

   	<div id="page-container" class="full-viewport uk-grid-row-large uk-grid-collapse" uk-grid>
      <div class="leftcol uk-width-1-5"></div>
      <div class="middlecol uk-width-3-5">
        <!-- <div id='workshop-title-div'> -->
         <div class='workshop-title'>Finding a Way Forward in VR Locomotion</div>
         <div class='workshop-subtitle'>IEEE VR Workshop 2021, April 2, 17:00-21:00 CEST</div>
<!--         </div> -->

        <div class="workshop-subsection">Overview</div>
        <p>No silver bullet exists for Virtual Reality (VR) locomotion. Many scientific papers have proposed new locomotion techniques, some have compared techniques, and there have been attempts to classify locomotion types into taxonomies. Our goal is to help unify research in this field by creating a shared community-sourced database of locomotion techniques and evaluation criteria. In this workshop, we will present LocomotionVault as our attempt to make a step in this direction. We hope to motivate the discussion of existing taxonomies, evaluation criteria, and challenges to unify research in this field.</p>

         <div class="workshop-subsection">Description</div>
         <p>In the last decade, numerous Virtual Reality (VR) locomotion techniques (LTs) have been invented, reinvented, combined and modified. Each of the LTs has a unique mix of idiosyncratic characteristics. Newly proposed LTs are usually compared to one or a few other LTs to find their advantages and disadvantages. Researchers have proposed several taxonomies and criteria for describing and evaluating LTs (e.g. in terms of the hardware employed, their granularity, accessibility, etc.). Yet, no agreement exists on which evaluation criteria or taxonomies are the most important when selecting an LT or designing a new one.</p>

        <p>Our goal is to unify research in the field by creating shared communitysourced evaluation criteria and datasets for locomotion in VR. To this end, we have created LocomotionVault (<a href="https://locomotionvault.github.io/">https://locomotionvault.github.io/</a>.  ), an interactive visual database of more than one hundred VR LTs from academia and industry. Each LT is described according to numerous attributes that we collated from existing VR taxonomies which give a similarity score between techniques.</p>


         <p>In this workshop, we aim to bring VR locomotion researchers together to discuss existing taxonomies and evaluation criteria for VR LTs, challenges in design and evaluation of LTs in such a rapidly-growing space, and potential community-driven tools and initiatives that can move the field forward. We aim to tackle these important topics with talks of the accepted abstracts followed by lively discussions with the attendees.</p>

         <div class="workshop-subsection">Workshop topics</div>
          <ul>
            <li>VR locomotion techniques/methods (Redirection, Teleportation, Navigation, Movement)</li>
            <li>Locomotion devices</li>
            <li>Evaluation criteria for VR locomotion (e.g., Usability, Accessibility, Cybersickness)</li>
            <li>Locomotion taxonomies</li>
          </ul>
         <div class="workshop-subsection">Format and submission guidelines</div>
        <p>Submissions should include a title, a list of authors, a 2-page description of the proposed topic in TVCG format. Additional pages can be considered on a case by case basis, but you should check with the workshop organizers (<a href="mailto:margon@microsoft.com">margon@microsoft.com</a>) before the submission deadline. Acceptable paper types are work-in-progress, research papers, position papers, or commentaries. Submissions will be reviewed by the organisers and accepted submissions will give a 20-minute talk with a panel discussion at the end of the session. At least one author must register for the workshop. Selected submissions will get the opportunity to be extended to articles to be considered for a special issue.</p>
	      <p>To submit your work, visit <a href="https://new.precisionconference.com/vr">https://new.precisionconference.com/vr</a></p>
        <div class="workshop-subsection">Important dates</div>
        <ul>
          <li>Submission deadline: January 29</li>
          <li>Notification of acceptance: January 31</li>
          <li>Camera-ready deadline: February 10</li>
        </ul>
        <div id='organizers'>
           <div class="workshop-subsection">Workshop organizers</div>
          <div class="organizers uk-grid-row-medium" uk-grid>
            <div class="leftcol uk-width-1-4"><img src="./Gifs/margonzalezfranco.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Mar Gonzalez-Franco, Microsoft Research margon@microsoft.com @twi_mar</h5>
              <p>Mar Gonzalez-Franco is a Researcher at Microsoft Research. She earned her PhD in Immersive Virtual Reality and Clinical Psychology under the supervision of Prof. Mel Slater at the Experimental Virtual Environments for Neuroscience and Technology Lab (EVENT-Lab), affiliated as a visiting student at the MIT MediaLab – Massachusetts Institute of Technology. During her PhD she produced anarchic hand experiences into healthy humans, as well as stabbed their virtual hands, indeed virtual reality is probably the only platform where you can do all of that and get away with the ethics committee. She then did a post-doc at University College London’s Virtual Environments and Computer Graphics (UCL-VECG) group. Willing to impact larger audiences she pivoted into industrial laboratories; she created and led an immersive tech lab at Airbus Group in the UK and later joined Traity as a Research Scientist, working on the creation of reputation standards for a user base of 4.5M.</p>
              <p>Altogether Dr Gonzalez-Franco explores how our brain perceives our body and she searches the underlying mechanisms that determine what is real and what is not. Technologically, she employs real-time computer graphics, HMDs and body tracking systems.</p>
            </div>
         <div class="leftcol uk-width-1-4"><img src="./Gifs/hastiseifi2.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Hasti Seifi, University of Copenhagen hs@di.ku.dk @hasti_seifi</h5>
              <p>Hasti Seifi is a tenure-track assistant professor in the Department of Computer Science at the University of Copenhagen. Previously, she was an NSERC postdoctoral fellow at the Max Planck Institute for Intelligent Systems with Dr. Katherine J. Kuchenbecker and a Ph.D. student in the Department of Computer Science at the University of British Columbia with Professor Karon E. MacLean.</p>
              <p>Her research is at the intersection of human-computer interaction, programmable touch technology (haptics), and social robotics. Specifically, Dr. Seifi studies how users interact with and make sense of haptic feedback from devices and robots through qualitative and quantitative studies. With this foundation, she designs touch experiences that are meaningful and pleasant, and she builds collections and software tools that facilitate creation and adaptation of touch experiences by endusers, novice designers, and haptics experts.</p>
            </div>
            <div class="leftcol uk-width-1-4"><img src="./Gifs/maxdiluca.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Massimiliano Di Luca, University of Birmingham m.diluca@bham.ac.uk @maxdiluca</h5>
              <p>Massimiliano Di Luca is senior lecturer at the University of Birmingham in the Computational Neuroscience and Cognitive Robotics research centre. He earned the Laurea in Psychology from the Università di Trieste in 2000 and the PhD in Cognitive Science from Brown University in 2006. During his carer, Dr Di Luca has been Scientist at the Max Planck Institute for Biological Cybernetics in Tübingen, Visiting Scientist at Oculus Research and Research Scientist at Facebook Reality Labs.</p>
              <p> Dr Di Luca performs both fundamental and applied research to capture the traits of effective sensory feedback and understand how users employ such stimuli. He uses psychophysical experiments, neuroimaging methods, and signal processing to discover patterns in user interactions and cognitive states. The leitmotiv of his research is to create computational models that constitute quantitative and testable theories about the underlying cognitive and neural processes.</p>
            </div>
          </div>

            


        </div>
		<br/><br/>
		<div id="participants">
		<div class="workshop-subsection">Participants and Submissions</div>
<table >

  <td valign=top >
  
  <img width=172 height=76
  src="workshop/image002.jpg"
  alt="A picture containing text, mountain, nature, valley&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top >
  <b>Revisiting Audiovisual Rotation Gains for Redirected Walking</b>
  <p >
  <p> 
  Andreas Junker, Carl
  Hutters, Daniel  Boonma Reipur, Lasse Embøl Sørensen,
  Niels Christian Nilsson, Evan Suma Rosenberg, Stefania Serafin</p>
  </td>
  <td valign=top >
  <p >
  <a href=" https://www.youtube.com/watch?v=47GRCKEQ5n4">
 Video</a></p>
  </td>
 </tr>
 <tr >
  <td valign=top >

  <p >
  <img border=0 width=172 height=108
  src="workshop/image004.jpg"
  alt="Chart&#10;&#10;Description automatically generated" >
  
  </p>
  </td>
  <td valign=top >
    <b>Redirection Using Alignment </b>
  <p>Niall L. Williams, Aniket Bera, Dinesh Manocha
  </p>
  </td>
  <td valign=top >
  <p >
  
<a href=" https://youtu.be/6jNlURaj-PU">
  Video</a></p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  <img border=0 width=146 height=112
  src="workshop/image006.jpg" >
  </td>
  <td valign=top >
<b>An Overview of Group Navigation in Multi-User Virtual Reality</b>
   
 <p>Tim Weissker,  
  Pauline Bimberg, Bernd Froehlich
  </p>
  </td>
  <td valign=top >
  <p >
  
  <a href="https://www.youtube.com/watch?v=r1L1-KGY8Cc">
 Video</a>
 
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=85
  src="workshop/image008.jpg"
  alt="A screenshot of a video game&#10;&#10;Description automatically generated with medium confidence"
  > 
 </p>
  </td>
  <td valign=top 
  >
  <b>Misc learning while making commercial games</b>
  <p>Katie Goode
  </p>
  </td>
  <td valign=top >
  <p> 
 <a
  href="https://www.youtube.com/watch?v=aM8XJx8hCII">
Video</a></p>
  </td>
 </tr>
 <tr >
  <td valign=top >
 
  <p >
  <img border=0 width=172 height=96
  src="workshop/image010.jpg"
  alt="Graphical user interface&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top >
   <b>Integrating Continuous and Teleporting VR Locomotion into a
  Seamless “ HyperJump” Paradigm  </b>
  <p   > 
  
  Ashu Adhikari, Daniel
  Zielasko, Alexander Bretin, Markus von der Heyde, Ernst Kruijff Bonn-Rhein-Sieg,
  Bernhard Riecke</p>
  </td>
  <td valign=top >
  <p >
  
  <a
  href=" https://www.youtube.com/watch?v=ARr9bv9LBmo">
 Video</a></p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=91
  src="workshop/image012.jpg"
  alt="Graphical user interface, application, website&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top   >
  <b>Continuous vs. Discontinuous (Teleport) Locomotion in VR: How
  Implications can Provide both Benefits and Disadvantages  </b>
  <p>Bernhard Riecke,  
  Daniel Zielasko
  </p>
  </td>
  <td valign=top >
  <p >
  
 <a href="https://www.youtube.com/watch?v=Abb7v02ZctE">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=167
  src="workshop/image014.jpg"
  alt="Text&#10;&#10;Description automatically generated with medium confidence"
  > 
 </p>
  </td>
  <td valign=top >
  <b>Direction  change of redirected walking
  via a single shoe height change 
 </b>
  <p >
  
  YanXiang 
  Zhang, Jiao Hong
  </p>
  </td>
  <td valign=top >
  <p >
  
  <a href="https://www.youtube.com/watch?v=g1N8R3xHe9Q">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=223 height=145
  src="workshop/image016.jpg"
  alt="Graphical user interface, diagram&#10;&#10;Description automatically generated"> 
 </p>
  </td>
  <td valign=top  >
  <b>Multisensory Teleportation in Virtual Reality Applications</b>
  <p > 
  Francesco Soave, 
  Ildar  Farkhatdinov,  Nick Bryan-Kinns</p>
  </td>
  <td valign=top >
  <p >
  
  <a href="https://www.youtube.com/watch?v=4ko8fb_VIC4">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
 
  <p >
  <img border=0 width=172 height=97
  src="workshop/image018.jpg"
  alt="Graphical user interface, text, application&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top > 
  <b>Evaluating VR Sickness in VR Locomotion Techniques</b>
  <p>Thomas van Gemert, Joanna Bergström
  </p>
  </td>
  <td valign=top >
  <p >
  
  <a
  href="https://www.youtube.com/watch?v=4Gr2DpoupAU&amp;feature=youtu.be">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=89
  src="workshop/image020.jpg"
  alt="A picture containing text, indoor&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top >
  <b>Combining Natural Techniques to Achieve Seamless Locomotion in
  Consumer VR Spaces</b>
  <p > 
  Hannah 
  Paulmann, Tim Mayer, Marc Barnes, Dennis 
  Briddigkeit, Frank Steinicke, Eike Langbehn</p>
  </td>
  <td valign=top >
  <p >
  
  <a
  href="https://cloud.curvaturegames.com/index.php/s/tt9ifcNQ45tFL3k">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
 <img border=0 width=172 height=57
  src="workshop/image022.jpg"
  alt="Chart&#10;&#10;Description automatically generated with medium confidence"
  >  
  </td>
  <td valign=top 
  ><b>An Overview and Analysis of Publications on Locomotion
  Taxonomies </b>
  <p 
  > Lisa
  Marie  Prinz,
 Tintu   Mathew, Simon  Klüber,
  Benjamin Weyers </p>
  </td>
  <td valign=top >
  <p >
  
  <a href="https://www.youtube.com/watch?v=H9JXavWlwL8">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=132
  src="workshop/image024.png" >
  
  </p>
  </td>
  <td valign=top 
  ><b>Impossible Open Spaces: Exploring the Effects of Occlusion on
  the Noticeability of Self-Overlapping Virtual Environments
  
  </b>
  <p>
  
  Claudiu-Bogdan 
  , Cristian Patras, Mantas 
  Cibulskis,  
  Norbert Varadi, Niels
  Christian Nilsson </p>
  </td>
  <td valign=top >
  <p >
  
  <a
  href="https://youtu.be/6yL446cDXaw">
  Video</a></p>
  </td>
 </tr>
 <tr >
  <td valign=top >
 
  <p >
  <img border=0 width=223 height=175
  src="workshop/image026.jpg"
  alt="Diagram&#10;&#10;Description automatically generated" >
  
  </p>
  <p>(Credit image: Emily Oldham) 
 </p>
  </td>
  <td valign=top 
  > <b>The Effectiveness of Locomotion Interfaces Depends on
  Self-Motion Cues, Environmental Cues, and the Individual</b>
  <p>Jonathan Kelly,  
  Stephen B. Gilbert
  </p>
  </td>
  <td valign=top ></td>
 </tr>
 <tr >
  <td valign=top >
  
  <img border=0 width=223 height=59
  src="workshop/image028.jpg"
  alt="A picture containing text&#10;&#10;Description automatically generated"
  > 
  </td>
  <td valign=top 
  ><b>Effects of a handlebar on standing VR locomotion</b>
  <p > 
  Paul Chojecki, David 
  Przewozny, Detlef  Runde, Mustafa-Tevfik
   Lafci, 
  Sebastian Bosse</p>
  </td>
  <td valign=top >
  <p >
  
  <a href="https://www.youtube.com/watch?v=u6b0RVWqvzI">Video</a>
  </p>
  </td>
 </tr>
 <tr >
  <td valign=top >
  
  <p >
  <img border=0 width=172 height=115
  src="workshop/image030.jpg"
  alt="Graphical user interface, website&#10;&#10;Description automatically generated"
  > 
 </p>
  </td>
  <td valign=top 
  ><b>Is Walking Necessary for Effective Locomotion and Interaction in
  VR?
  </b>
  <p 
  > 
  Abraham M. Hashemian, Ashu
  Adhikari, Ivan A Aguilar, Ernst  Kruijff Bonn-Rhein-Sieg,
  Markus von der Heyde, Bernhard Riecke</p>
  </td>
  <td valign=top >
  <p >
  
 <a
  href="https://youtu.be/aReO8OwSS2Y">
  Video</a></p>
  </td>
 </tr>
</table>
		</div>
      <div class="rightcol uk-width-1-5"></div>
    </div>
    </div>


    <div id="footer-area" class="uk-grid-collapse" uk-grid>
          <div class="leftcol uk-width-1-5"></div>
          <div class="middlecol uk-width-3-5">For questions and comments, please contact <a href="mailto:margon@microsoft.com">margon@microsoft.com</a>.</div>
          <div class="rightcol uk-width-1-5"></div>
    </div>
      
   </body>
</html>

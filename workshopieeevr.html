<!DOCTYPE html>
<html lang = "en">
   <head>
      
<!--       <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"> -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/css/uikit.min.css" />
	<script src="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/js/uikit.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/uikit@3.5.5/dist/js/uikit-icons.min.js"></script>
   <script src="./libs/jquery-3.5.1.min.js" type="text/javascript"></script>
	<link href="./style.css" rel="stylesheet">
   </head>

   <body>
    <header>
      <div id="logo-area" uk-grid>
       <a href="https://locomotionvault.github.io/" class="uk-logo uk-width-2-3">Locomotion Vault</a>
          <!--  <div class="uk-width-1-3 uk-margin-small-bottom" uk-grid>
           </div> -->
      </div>
    </header>

    <div class="teaser">
      <img src="./Gifs/TeaserFull.jpg"></img>
    </div>

   	<div id="page-container" class="full-viewport uk-grid-row-large uk-grid-collapse" uk-grid>
      <div class="leftcol uk-width-1-5"></div>
      <div class="middlecol uk-width-3-5">
        <!-- <div id='workshop-title-div'> -->
         <div class='workshop-title'>Finding a Way Forward in VR Locomotion</div>
         <div class='workshop-subtitle'>IEEE VR Workshop 2021, March 28, Lisbon</div>
<!--         </div> -->

        <div class="workshop-subsection">Overview</div>
        <p>No silver bullet exists for Virtual Reality (VR) locomotion. Many scientific papers have proposed new locomotion techniques, some have compared techniques, and there have been attempts to classify locomotion types into taxonomies. Our goal is to help unify research in this field by creating a shared community-sourced database of locomotion techniques and evaluation criteria. In this workshop, we will present LocomotionVault as our attempt to make a step in this direction. We hope to motivate the discussion of existing taxonomies, evaluation criteria, and challenges to unify research in this field.</p>

         <div class="workshop-subsection">Description</div>
         <p>In the last decade, numerous Virtual Reality (VR) locomotion techniques (LTs) have been invented, reinvented, combined and modified. Each of the LTs has a unique mix of idiosyncratic characteristics. Newly proposed LTs are usually compared to one or a few other LTs to find their advantages and disadvantages. Researchers have proposed several taxonomies and criteria for describing and evaluating LTs (e.g. in terms of the hardware employed, their granularity, accessibility, etc.). Yet, no agreement exists on which evaluation criteria or taxonomies are the most important when selecting an LT or designing a new one.</p>

        <p>Our goal is to unify research in the field by creating shared communitysourced evaluation criteria and datasets for locomotion in VR. To this end, we have created LocomotionVault (<a href="https://locomotionvault.github.io/">https://locomotionvault.github.io/</a>.  ), an interactive visual database of more than one hundred VR LTs from academia and industry. Each LT is described according to numerous attributes that we collated from existing VR taxonomies which give a similarity score between techniques.</p>


         <p>In this workshop, we aim to bring VR locomotion researchers together to discuss existing taxonomies and evaluation criteria for VR LTs, challenges in design and evaluation of LTs in such a rapidly-growing space, and potential community-driven tools and initiatives that can move the field forward. We aim to tackle these important topics with talks of the accepted abstracts followed by lively discussions with the attendees.</p>

         <div class="workshop-subsection">Workshop topics</div>
          <ul>
            <li>VR locomotion techniques/methods (Redirection, Teleportation, Navigation, Movement)</li>
            <li>Locomotion devices</li>
            <li>Evaluation criteria for VR locomotion (e.g., Usability, Accessibility, Cybersickness)</li>
            <li>Locomotion taxonomies</li>
          </ul>
         <div class="workshop-subsection">Format and submission guidelines</div>
        <p>Submissions should include a title, a list of authors, a 2-page description of the proposed topic in TVCG format. Additional pages can be considered on a case by case basis, but you should check with the workshop organizers (<a href="mailto:margon@microsoft.com">margon@microsoft.com</a>) before the submission deadline. Acceptable paper types are work-in-progress, research papers, position papers, or commentaries. Submissions will be reviewed by the organisers and accepted submissions will give a 20-minute talk with a panel discussion at the end of the session. At least one author must register for the workshop. Selected submissions will get the opportunity to be extended to articles to be considered for a special issue.</p>
	      <p>To submit your work, visit <a href="https://new.precisionconference.com/vr">https://new.precisionconference.com/vr</a></p>
        <div class="workshop-subsection">Important dates</div>
        <ul>
          <li>Submission deadline: January 29</li>
          <li>Notification of acceptance: January 31</li>
          <li>Camera-ready deadline: February 10</li>
        </ul>
        <div id='organizers'>
           <div class="workshop-subsection">Workshop organizers</div>
          <div class="organizers uk-grid-row-medium" uk-grid>
            <div class="leftcol uk-width-1-4"><img src="./Gifs/margonzalezfranco.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Mar Gonzalez-Franco, Microsoft Research margon@microsoft.com @twi_mar</h5>
              <p>Mar Gonzalez-Franco is a Researcher at Microsoft Research. She earned her PhD in Immersive Virtual Reality and Clinical Psychology under the supervision of Prof. Mel Slater at the Experimental Virtual Environments for Neuroscience and Technology Lab (EVENT-Lab), affiliated as a visiting student at the MIT MediaLab – Massachusetts Institute of Technology. During her PhD she produced anarchic hand experiences into healthy humans, as well as stabbed their virtual hands, indeed virtual reality is probably the only platform where you can do all of that and get away with the ethics committee. She then did a post-doc at University College London’s Virtual Environments and Computer Graphics (UCL-VECG) group. Willing to impact larger audiences she pivoted into industrial laboratories; she created and led an immersive tech lab at Airbus Group in the UK and later joined Traity as a Research Scientist, working on the creation of reputation standards for a user base of 4.5M.</p>
              <p>Altogether Dr Gonzalez-Franco explores how our brain perceives our body and she searches the underlying mechanisms that determine what is real and what is not. Technologically, she employs real-time computer graphics, HMDs and body tracking systems.</p>
            </div>
         <div class="leftcol uk-width-1-4"><img src="./Gifs/hastiseifi2.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Hasti Seifi, University of Copenhagen hs@di.ku.dk @hasti_seifi</h5>
              <p>Hasti Seifi is a tenure-track assistant professor in the Department of Computer Science at the University of Copenhagen. Previously, she was an NSERC postdoctoral fellow at the Max Planck Institute for Intelligent Systems with Dr. Katherine J. Kuchenbecker and a Ph.D. student in the Department of Computer Science at the University of British Columbia with Professor Karon E. MacLean.</p>
              <p>Her research is at the intersection of human-computer interaction, programmable touch technology (haptics), and social robotics. Specifically, Dr. Seifi studies how users interact with and make sense of haptic feedback from devices and robots through qualitative and quantitative studies. With this foundation, she designs touch experiences that are meaningful and pleasant, and she builds collections and software tools that facilitate creation and adaptation of touch experiences by endusers, novice designers, and haptics experts.</p>
            </div>
            <div class="leftcol uk-width-1-4"><img src="./Gifs/maxdiluca.jpeg"></img></div>
            <div class="middlecol uk-width-3-4">
              <h5>Massimiliano Di Luca, University of Birmingham m.diluca@bham.ac.uk @maxdiluca</h5>
              <p>Massimiliano Di Luca is senior lecturer at the University of Birmingham in the Computational Neuroscience and Cognitive Robotics research centre. He earned the Laurea in Psychology from the Università di Trieste in 2000 and the PhD in Cognitive Science from Brown University in 2006. During his carer, Dr Di Luca has been Scientist at the Max Planck Institute for Biological Cybernetics in Tübingen, Visiting Scientist at Oculus Research and Research Scientist at Facebook Reality Labs.</p>
              <p> Dr Di Luca performs both fundamental and applied research to capture the traits of effective sensory feedback and understand how users employ such stimuli. He uses psychophysical experiments, neuroimaging methods, and signal processing to discover patterns in user interactions and cognitive states. The leitmotiv of his research is to create computational models that constitute quantitative and testable theories about the underlying cognitive and neural processes.</p>
            </div>
          </div>

            


        </div>
      <div class="rightcol uk-width-1-5"></div>
    </div>
    </div>


    <div id="footer-area" class="uk-grid-collapse" uk-grid>
          <div class="leftcol uk-width-1-5"></div>
          <div class="middlecol uk-width-3-5"><span>For questions and comments, please contact <a href="mailto:margon@microsoft.com">margon@microsoft.com</a>.</span></div>
          <div class="rightcol uk-width-1-5"></div>
    </div>
      
   </body>
</html>
